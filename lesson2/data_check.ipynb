{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyP8p8AcUOIR3/UkbFqOdn2U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data Verification for Cleaned Sentiment Analysis Dataset"],"metadata":{"id":"u8gFmP7NCi2v"}},{"cell_type":"markdown","source":["In the provided Python exercise, a series of tests were formulated and executed to verify the integrity and structure of a cleaned dataset obtained from a **``Weights & Biases (wandb)``** artifact named **``clean_data``**. The dataset comprises text files categorized into positive and negative sentiments, stored in two directories named **``pos``** and **``neg``**. The tests were conducted to ensure that the data is in the expected format and adheres to certain criteria before proceeding with further analysis or modeling tasks.\n","\n","Here’s a summary of the tests conducted:\n","\n","1. **Directory Existence**:\n","Checked whether the directories **``pos``** and **``neg``** exist within the downloaded artifact.\n","\n","2. **Instance Count**:\n","Verified that there are at least 500 instances (files) in each of the **``pos``** and **``neg``** directories.\n","\n","3. **Duplicate Verification**:\n","Ensured that there are no duplicate files within and across the **``pos``** and **``neg``** directories by comparing filenames. This test operates under the assumption that unique filenames correspond to unique content.\n","\n","4. **File Non-emptiness**:\n","Checked that each file in the **``pos``** and **``neg``** directories is not empty, ensuring that every file contains some data.\n","\n","These tests were structured within a Python script using the **pytest** framework. The script initiates a **wandb** run to log any potential issues and utilizes a **fixture** to download the **``clean_data``** artifact from **wandb**, providing a local path to the data for the tests. Each test is defined as a separate function, and the pytest command at the end of the script executes all tests, providing a detailed output of the results.\n","\n","This verification process is crucial as it ensures the cleaned dataset is well-structured, free of duplicates, and ready for subsequent analysis or machine learning tasks. By logging the results to **wandb**, there's a traceable record of the data verification process, which contributes to the reproducibility and reliability of the analysis pipeline."],"metadata":{"id":"nBvHHPryCp7j"}},{"cell_type":"markdown","source":["## Install, load libraries and setup wandb"],"metadata":{"id":"FYSHiNN6EJli"}},{"cell_type":"code","source":["!pip install wandb pytest pytest-sugar"],"metadata":{"id":"gRAN8xBtERbA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Login to Weights & Biases\n","!wandb login --relogin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4u5C9COEmHU","executionInfo":{"status":"ok","timestamp":1699231210089,"user_tz":180,"elapsed":11684,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"33304a7e-2044-4635-ed5f-cdb8f6b3b441"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"code","source":["import wandb"],"metadata":{"id":"KhR0tKxOG5oW","executionInfo":{"status":"ok","timestamp":1699231806298,"user_tz":180,"elapsed":1222,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Pytest\n"],"metadata":{"id":"Ez1uRlW3E1NW"}},{"cell_type":"markdown","source":["### How pytest discovers tests\n"],"metadata":{"id":"2QFyXncrE3Iv"}},{"cell_type":"markdown","source":["**pytests** uses the following [conventions](https://docs.pytest.org/en/latest/goodpractices.html#conventions-for-python-test-discovery) to automatically discovering tests:\n","\n","1. files with tests should be called **``test_*.py``** or **``*_test.py``**\n","2. test function name should start with **``test_``**"],"metadata":{"id":"HIsOwULYE6zi"}},{"cell_type":"markdown","source":["### Fixture\n"],"metadata":{"id":"icOEJVUkFMQU"}},{"cell_type":"markdown","source":["\n","An important aspect when using **``pytest``** is understanding the fixture's scope works.\n","\n","The scope of the fixture can have a few legal values, described [here](https://docs.pytest.org/en/6.2.x/fixture.html#fixture-scopes). We are going to consider only **``session``** and **``function``**: with the former, the fixture is executed only once in a pytest session and the value it returns is used for all the tests that need it; with the latter, every test function gets a fresh copy of the data. This is useful if the tests modify the input in a way that make the other tests fail, for example."],"metadata":{"id":"paBlWNdbFP3g"}},{"cell_type":"markdown","source":["## Create and run a test file"],"metadata":{"id":"shgdLFnPFw-5"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oupgsNlVCbSC","executionInfo":{"status":"ok","timestamp":1699231678693,"user_tz":180,"elapsed":4,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"b816e631-2bca-49c6-9f83-e67397a473d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing test_data.py\n"]}],"source":["%%file test_data.py\n","import pytest\n","import wandb\n","import os\n","\n","# This is global so all tests are collected under the same run\n","run = wandb.init(project=\"sentiment_analysis\", job_type=\"data_checks\")\n","\n","@pytest.fixture(scope=\"session\")\n","def data():\n","    # Download the clean_data artifact\n","    local_path = run.use_artifact(\"clean_data:latest\").download()\n","    return local_path\n","\n","def test_directory_existence(data):\n","    \"\"\"\n","    Test that the 'pos' and 'neg' directories exist\n","    \"\"\"\n","    assert os.path.isdir(os.path.join(data, 'pos'))\n","    assert os.path.isdir(os.path.join(data, 'neg'))\n","\n","def test_instance_count(data):\n","    \"\"\"\n","    Test that there are at least 500 instances in 'pos' and 'neg' directories\n","    \"\"\"\n","    assert len(os.listdir(os.path.join(data, 'pos'))) >= 500\n","    assert len(os.listdir(os.path.join(data, 'neg'))) >= 500\n","\n","def test_no_duplicates(data):\n","    \"\"\"\n","    Test that there are no duplicate files within and across 'pos' and 'neg' directories\n","    \"\"\"\n","    pos_files = set(os.listdir(os.path.join(data, 'pos')))\n","    neg_files = set(os.listdir(os.path.join(data, 'neg')))\n","    # No duplicates within directories\n","    assert len(pos_files) == len(os.listdir(os.path.join(data, 'pos')))\n","    assert len(neg_files) == len(os.listdir(os.path.join(data, 'neg')))\n","    # No duplicates across directories\n","    assert len(pos_files.intersection(neg_files)) == 0\n","\n","def test_non_empty_files(data):\n","    \"\"\"\n","    Test that each file in 'pos' and 'neg' directories is not empty\n","    \"\"\"\n","    for folder in ['pos', 'neg']:\n","        for file in os.listdir(os.path.join(data, folder)):\n","            assert os.path.getsize(os.path.join(data, folder, file)) > 0"]},{"cell_type":"code","source":["# run tests\n","!pytest . -vv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdNZFNTuGRnr","executionInfo":{"status":"ok","timestamp":1699231730018,"user_tz":180,"elapsed":39567,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"04ec2e32-fe11-4913-dded-8d103e829ad1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mTest session starts (platform: linux, Python 3.10.12, pytest 7.4.3, pytest-sugar 0.9.7)\u001b[0m\n","cachedir: .pytest_cache\n","rootdir: /content\n","plugins: sugar-0.9.7, anyio-3.7.1\n","collected 4 items                                                                                  \u001b[0m\n","\n"," \u001b[36mtest_data.py\u001b[0m::test_directory_existence\u001b[0m \u001b[32m✓\u001b[0m                                             \u001b[32m25% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█▌       \u001b[0m\n"," \u001b[36mtest_data.py\u001b[0m::test_instance_count\u001b[0m \u001b[32m✓\u001b[0m                                                  \u001b[32m50% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m██     \u001b[0m\n"," \u001b[36mtest_data.py\u001b[0m::test_no_duplicates\u001b[0m \u001b[32m✓\u001b[0m                                                   \u001b[32m75% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m██\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█▌  \u001b[0m\n"," \u001b[36mtest_data.py\u001b[0m::test_non_empty_files\u001b[0m \u001b[32m✓\u001b[0m                                                \u001b[32m100% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m██\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m██\u001b[0m\n","\n","Results (31.78s):\n","\u001b[32m       4 passed\u001b[0m\n"]}]},{"cell_type":"code","source":["# Optionally, finish the wandb run\n","wandb.finish()"],"metadata":{"id":"wwW-7f15Geru","executionInfo":{"status":"ok","timestamp":1699231811884,"user_tz":180,"elapsed":1,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jJ2cYN4WG8Qf"},"execution_count":null,"outputs":[]}]}