{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqLPgyfzaWIBpRxA2Iv6MG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Exploratory Data Analysis (EDA) of Text Data for Sentiment Analysis\n"],"metadata":{"id":"HtlySbWoS644"}},{"cell_type":"markdown","source":["\n","In this Exploratory Data Analysis (EDA), we delve into a dataset comprising text files categorized into positive and negative sentiments, aimed at understanding its structure and characteristics before proceeding with sentiment analysis tasks. The dataset is housed in a Weights & Biases (wandb) artifact under the project **`my_user/sentiment_analysis`**, with the artifact name **`txt_sentoken:v0`**.\n","\n","The dataset is organized into two subfolders, **`pos`** and **`neg`**, each containing 1,000 text files representing positive and negative sentiments respectively.\n"],"metadata":{"id":"VjcubDYzS-E6"}},{"cell_type":"markdown","source":["\n","**1. Data Overview:**\n","   - **File Count:** We first verify the count of files in each subfolder to ensure there are indeed 1,000 files in both `pos` and `neg` subfolders.\n","   - **File Size Analysis:** We analyze the size of the files (in bytes) to understand the variation in text length across positive and negative sentiments.\n","\n","**2. File Size Distribution:**\n","   - A histogram is generated to visualize the distribution of file sizes in both `pos` and `neg` subfolders. This aids in understanding the spread and central tendency of text lengths in our dataset.\n","\n","The EDA is performed using a Python script, which:\n","   - Initializes a wandb run to log the analysis results and visualizations.\n","   - Fetches the artifact from wandb and downloads its content to the local directory.\n","   - Iterates through each subfolder to count the number of files and collect file size data.\n","   - Logs the file count information to wandb.\n","   - Creates and saves a histogram of file sizes, which is also logged to wandb.\n","\n","This preliminary analysis provides insights into the basic characteristics of the dataset, setting the stage for further analyses and preprocessing steps necessary for subsequent sentiment analysis tasks. Logging the analysis results and visualizations to wandb ensures a traceable and reproducible data science workflow."],"metadata":{"id":"UkJ_KejvTISs"}},{"cell_type":"markdown","source":["## Install and load libraries"],"metadata":{"id":"nW-xyxepTOTl"}},{"cell_type":"code","source":["!pip install wandb"],"metadata":{"id":"HD763edrTXPd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Login to Weights & Biases\n","!wandb login --relogin"],"metadata":{"id":"W7nwhVY5Ti1M"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82UMcxeKQzxm"},"outputs":[],"source":["import os\n","import matplotlib.pyplot as plt\n","import wandb"]},{"cell_type":"markdown","source":["## Download sentiment analysis data artifact from Wandb"],"metadata":{"id":"NIjeHIPGT5oK"}},{"cell_type":"code","source":["# Initialize wandb run\n","wandb.init(project='sentiment_analysis', save_code=True)\n","\n","# Get the artifact\n","artifact = wandb.use_artifact('txt_sentoken:v0')\n","\n","# Download the content of the artifact to the local directory\n","artifact_dir = artifact.download()"],"metadata":{"id":"UOiDxaaJTpBw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Subfolders 'pos' and 'neg'\n","subfolders = ['pos', 'neg']\n","\n","# Initialize lists to store results\n","file_counts = []\n","file_sizes = {'pos': [], 'neg': []}\n","\n","# Iterate over each subfolder\n","for subfolder in subfolders:\n","    # Full path to the subfolder\n","    subfolder_path = os.path.join(artifact_dir, subfolder)\n","\n","    # Get the list of files in the subfolder\n","    files = os.listdir(subfolder_path)\n","\n","    # Add the file count to the list\n","    file_counts.append(len(files))\n","\n","    # Get and store the size of each file\n","    for file in files:\n","        file_path = os.path.join(subfolder_path, file)\n","        file_size = os.path.getsize(file_path)  # size in bytes\n","        file_sizes[subfolder].append(file_size)\n","\n","# Log the file counts to wandb\n","for subfolder, count in zip(subfolders, file_counts):\n","    wandb.log({f'Number of files in {subfolder}': count})"],"metadata":{"id":"icjEt88BUCv9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Histogram of file sizes\n","plt.figure(figsize=(10, 5))\n","plt.hist(file_sizes['pos'], bins=30, alpha=0.5, label='Positive Texts')\n","plt.hist(file_sizes['neg'], bins=30, alpha=0.5, label='Negative Texts')\n","plt.xlabel('File Size (bytes)')\n","plt.ylabel('Frequency')\n","plt.legend(loc='upper right')\n","plt.title('Distribution of File Sizes')\n","plt.savefig('file_size_distribution.png')  # Save the plot to a file\n","plt.show()\n","plt.close()\n","\n","# Log the histogram image to wandb\n","wandb.log({\"File Size Distribution\": wandb.Image('file_size_distribution.png')})"],"metadata":{"id":"2UdQyiWPlHb0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optionally, finish the wandb run (if this is the end of your script)\n","wandb.finish()"],"metadata":{"id":"lj6ZPwUUlOyj"},"execution_count":null,"outputs":[]}]}