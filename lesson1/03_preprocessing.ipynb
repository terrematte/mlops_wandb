{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Analysis implemented and available at https://github.com/ivanovitchm/mlops/tree/main/lessons/week_09\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/terrematte/mlops_wandb/blob/main/lesson1/03_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "VDkam2H_Z3n6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning and Deduplication for Sentiment Analysis Dataset"
      ],
      "metadata": {
        "id": "TbCmaSan8Mr5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this data cleaning exercise, the objective was to identify and remove duplicate text files from a sentiment analysis dataset hosted on **``Weights & Biases (wandb)``**, under the project **`my_user/sentiment_analysis`** with the artifact name **`txt_sentoken:v0`**. The dataset contains text files categorized into positive and negative sentiments, organized within two subfolders named **`pos`** and **`neg`**.\n",
        "\n",
        "Here are the steps undertaken to achieve the deduplication and re-upload the cleaned data back to wandb:\n",
        "\n",
        "1. **Wandb Initialization:**\n",
        "   - A wandb run was initialized using **`wandb.init()`** under the project **`my_user/sentiment_analysis`** with the run name **`data_cleaning`**.\n",
        "\n",
        "2. **Artifact Retrieval:**\n",
        "   - The **`txt_sentoken:v0`** artifact was retrieved from wandb using `wandb.use_artifact()` and its content was downloaded to the local directory using **`artifact.download()`**.\n",
        "\n",
        "3. **Hash Calculation:**\n",
        "   - A function named **`calculate_hash`** was defined to compute the SHA-256 hash of a file, which serves as a unique identifier for the file content.\n",
        "\n",
        "4. **Duplicate Identification and Removal:**\n",
        "   - A function named **`identify_and_remove_duplicates`** was defined to traverse through each file in the **`pos`** and **`neg`** subfolders, calculate the SHA-256 hash, and identify duplicate files. If a duplicate file was identified (based on the hash), it was removed from the directory using **`os.remove()`**.\n",
        "\n",
        "5. **Cleaned Data Artifact Creation:**\n",
        "   - A new wandb artifact named **`clean_data`** was created to hold the cleaned dataset. This artifact was described as a dataset with duplicates removed.\n",
        "\n",
        "6. **Adding Cleaned Data to the Artifact:**\n",
        "   - The cleaned data directories (**`pos`** and **`neg`** subfolders) were added to the **`clean_data`** artifact using **`clean_data_artifact.add_dir()`**.\n",
        "\n",
        "7. **Logging the Cleaned Data Artifact to Wandb:**\n",
        "   - The **`clean_data`** artifact was logged to wandb using **`wandb.log_artifact()`**, making the cleaned dataset available for further analysis or modeling.\n",
        "\n",
        "8. **Wandb Run Termination (Optional):**\n",
        "   - Optionally, the wandb run was concluded using **`wandb.finish()`** to indicate the end of the data cleaning run.\n",
        "\n",
        "Through these steps, a systematic approach was followed to download the original dataset, identify and remove duplicate files, and re-upload the cleaned dataset as a new artifact on wandb, ensuring a clean, deduplicated dataset ready for subsequent analysis or machine learning tasks."
      ],
      "metadata": {
        "id": "Ph10GOMv8WX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and load libraries"
      ],
      "metadata": {
        "id": "uvyoasp29etb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "JpyrV7Cs9m0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6a8adbe-a806-4d17-b957-d35138c49e41"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Login to Weights & Biases\n",
        "!wandb login --relogin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zBDkbT59rom",
        "outputId": "eec31ed3-70ed-4b70-8d8b-00bfb2ade94e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import os\n",
        "import wandb\n",
        "import shutil"
      ],
      "metadata": {
        "id": "AwZX0c4K9Zsl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wandb Initialization and Artifact Retrieval"
      ],
      "metadata": {
        "id": "LuUI0GVw-SD2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "JPcisDSm7210",
        "outputId": "690ff37f-987a-4834-c39c-57489d3c9775"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241126_030022-812p9efk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/terrematte/sentiment_analysis/runs/812p9efk' target=\"_blank\">ethereal-snow-8</a></strong> to <a href='https://wandb.ai/terrematte/sentiment_analysis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/terrematte/sentiment_analysis' target=\"_blank\">https://wandb.ai/terrematte/sentiment_analysis</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/terrematte/sentiment_analysis/runs/812p9efk' target=\"_blank\">https://wandb.ai/terrematte/sentiment_analysis/runs/812p9efk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   2000 of 2000 files downloaded.  \n"
          ]
        }
      ],
      "source": [
        "# Initialize wandb run\n",
        "wandb.init(project='sentiment_analysis', job_type=\"preprocessing\")\n",
        "\n",
        "# Get the artifact\n",
        "artifact = wandb.use_artifact('txt_sentoken:v0')\n",
        "\n",
        "# Download the content of the artifact to the local directory\n",
        "artifact_dir = artifact.download()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hash Calculation and Duplicate Identification and Removal"
      ],
      "metadata": {
        "id": "VYMQ5PKQ-zZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_hash(file_path):\n",
        "    \"\"\"Calculate SHA-256 hash of a file.\"\"\"\n",
        "    sha256_hash = hashlib.sha256()\n",
        "    with open(file_path,\"rb\") as f:\n",
        "        # Read and update hash in chunks of 4K\n",
        "        for byte_block in iter(lambda: f.read(4096),b\"\"):\n",
        "            sha256_hash.update(byte_block)\n",
        "    return sha256_hash.hexdigest()\n",
        "\n",
        "def identify_and_remove_duplicates(folder_path):\n",
        "    \"\"\"Identify duplicate files in a folder and remove them.\"\"\"\n",
        "    file_hashes = {}\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            file_hash = calculate_hash(file_path)\n",
        "            if file_hash in file_hashes:\n",
        "                log_message = f'Removing duplicate: {file_path}'\n",
        "                wandb.log({'log': log_message})\n",
        "                os.remove(file_path)\n",
        "            else:\n",
        "                file_hashes[file_hash] = file_path\n",
        "\n",
        "# Paths to 'pos' and 'neg' subfolders\n",
        "pos_folder_path = os.path.join(artifact_dir, 'pos')\n",
        "neg_folder_path = os.path.join(artifact_dir, 'neg')\n",
        "\n",
        "# Identify and remove duplicates in 'pos' and 'neg' subfolders\n",
        "identify_and_remove_duplicates(pos_folder_path)\n",
        "identify_and_remove_duplicates(neg_folder_path)"
      ],
      "metadata": {
        "id": "ZFMjAMAb-N08"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaned Data Artifact Creation and Adding Cleaned Data to the Artifact"
      ],
      "metadata": {
        "id": "rJSuWc7B_eXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new artifact for the clean data\n",
        "clean_data_artifact = wandb.Artifact(\n",
        "    name='clean_data',\n",
        "    type='CleanData',\n",
        "    description='Cleaned dataset with duplicates removed'\n",
        ")\n",
        "\n",
        "# Add the cleaned data directories to the clean_data artifact\n",
        "clean_data_artifact.add_dir(pos_folder_path, name='pos')\n",
        "clean_data_artifact.add_dir(neg_folder_path, name='neg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10nFgqQ7-6kq",
        "outputId": "5d89c9a5-7129-438d-cb12-3323d1117ebe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/artifacts/txt_sentoken:v0/pos)... Done. 0.7s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/artifacts/txt_sentoken:v0/neg)... Done. 0.7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logging the Cleaned Data Artifact to Wandb and Terminate"
      ],
      "metadata": {
        "id": "fkSEl4bEAAF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Log the clean_data artifact to wandb\n",
        "wandb.log_artifact(clean_data_artifact)\n",
        "\n",
        "# Optionally, finish the wandb run (if this is the end of your script)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "Y1hyCdC0_4a2",
        "outputId": "8a4b9a8c-0395-4e72-dcc3-1c4327373721"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ethereal-snow-8</strong> at: <a href='https://wandb.ai/terrematte/sentiment_analysis/runs/812p9efk' target=\"_blank\">https://wandb.ai/terrematte/sentiment_analysis/runs/812p9efk</a><br/> View project at: <a href='https://wandb.ai/terrematte/sentiment_analysis' target=\"_blank\">https://wandb.ai/terrematte/sentiment_analysis</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241126_030022-812p9efk/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tWFFHSY7AFIt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}